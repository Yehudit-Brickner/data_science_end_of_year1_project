{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data science part 2 finale project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yehudit Brickner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we need to take the results from last semesters project of classification and try to get better results.\n",
    "<br>\n",
    "my best result from last semester with out getting rid of rows was 0.8675 pecent correct.\n",
    "<br>\n",
    "I will try to get better results this time using different models we learned this semester.\n",
    "<br>\n",
    "Because last semester I didnt divide my data and then normalize it, I will be doing that this semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports that i will need\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imprting the data\n",
    "df0=pd.read_csv(r'C:\\Users\\nechd\\Desktop\\StudentsPerformance.csv')\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none        0.72           0.72           0.74  \n",
       "1               completed        0.69           0.90           0.88  \n",
       "2                    none        0.90           0.95           0.93  \n",
       "3                    none        0.47           0.57           0.44  \n",
       "4                    none        0.76           0.78           0.75  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking the features with numeric values and dividing by 100, so that they are between 0 and 1.\n",
    "df0['math score']=df0['math score'].div(100)\n",
    "df0['reading score']=df0['reading score'].div(100)\n",
    "df0['writing score']=df0['writing score'].div(100)\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>avg_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.726667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.823333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.926667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.493333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.763333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \\\n",
       "0                    none        0.72           0.72           0.74   \n",
       "1               completed        0.69           0.90           0.88   \n",
       "2                    none        0.90           0.95           0.93   \n",
       "3                    none        0.47           0.57           0.44   \n",
       "4                    none        0.76           0.78           0.75   \n",
       "\n",
       "   avg_scores  \n",
       "0    0.726667  \n",
       "1    0.823333  \n",
       "2    0.926667  \n",
       "3    0.493333  \n",
       "4    0.763333  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a column averge score, taking all grades adding them together and dividing by 3.\n",
    "avg_scores = df0.loc[: , \"math score\":\"writing score\"]\n",
    "df0['avg_scores']=avg_scores.mean(axis=1)\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the data frame into train, test\n",
    "train_set, test_set = train_test_split(df0, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 0.6470048309178743\n",
      "B 0.6539433551198257\n",
      "C 0.6747692307692305\n",
      "D 0.6936798679867988\n",
      "E 0.733563218390805\n",
      "\n",
      "S 0.7128680688336523\n",
      "FR 0.6228279181708781\n",
      "\n",
      "SHS 0.6599270072992705\n",
      "HS 0.6355974842767297\n",
      "SCO 0.6865750915750919\n",
      "BA 0.7298958333333331\n",
      "M 0.7177304964539005\n",
      "AS 0.6990130353817507\n",
      "\n",
      "N 0.6535316698656425\n",
      "CO 0.7342771804062125\n"
     ]
    }
   ],
   "source": [
    "# I want to  to scale the data, so to do that i will cange all catagory.subcatagory to the average of that catagory.subcatagory, values from the avg column then diivde by 100.\n",
    "\n",
    "# scaling the data for the training set\n",
    "\n",
    "A=train_set.loc[train_set['race/ethnicity']=='group A']\n",
    "print(\"A\",A[\"avg_scores\"].mean())\n",
    "B=train_set.loc[train_set['race/ethnicity']=='group B']\n",
    "print(\"B\",B[\"avg_scores\"].mean())\n",
    "C=train_set.loc[train_set['race/ethnicity']=='group C']\n",
    "print(\"C\",C[\"avg_scores\"].mean())\n",
    "D=train_set.loc[train_set['race/ethnicity']=='group D']\n",
    "print(\"D\",D[\"avg_scores\"].mean())\n",
    "E=train_set.loc[train_set['race/ethnicity']=='group E']\n",
    "print(\"E\",E[\"avg_scores\"].mean())\n",
    "\n",
    "print()\n",
    "\n",
    "S=train_set.loc[train_set['lunch']=='standard']\n",
    "print(\"S\",S[\"avg_scores\"].mean())\n",
    "FR=train_set.loc[train_set['lunch']=='free/reduced']\n",
    "print(\"FR\",FR[\"avg_scores\"].mean())\n",
    "\n",
    "print()\n",
    "\n",
    "SHS=train_set.loc[train_set['parental level of education']=='some high school']\n",
    "print(\"SHS\",SHS[\"avg_scores\"].mean())\n",
    "HS=train_set.loc[train_set['parental level of education']=='high school']\n",
    "print(\"HS\",HS[\"avg_scores\"].mean())\n",
    "SCO=train_set.loc[train_set['parental level of education']=='some college']\n",
    "print(\"SCO\",SCO[\"avg_scores\"].mean())\n",
    "BA=train_set.loc[train_set['parental level of education']==\"bachelor's degree\"]\n",
    "print(\"BA\",BA[\"avg_scores\"].mean())\n",
    "M=train_set.loc[train_set['parental level of education']==\"master's degree\"]\n",
    "print(\"M\",M[\"avg_scores\"].mean())\n",
    "AS=train_set.loc[train_set['parental level of education']==\"associate's degree\"]\n",
    "print(\"AS\",AS[\"avg_scores\"].mean())\n",
    "\n",
    "print()\n",
    "\n",
    "N=train_set.loc[train_set['test preparation course']==\"none\"]\n",
    "print(\"N\",N[\"avg_scores\"].mean())\n",
    "CO=train_set.loc[train_set['test preparation course']==\"completed\"]\n",
    "print(\"CO\",CO[\"avg_scores\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>avg_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.846667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.646667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender race/ethnicity parental level of education lunch  \\\n",
       "29       0           0.69                        0.71  0.71   \n",
       "535      0           0.67                        0.72  0.62   \n",
       "695      0           0.69                        0.68  0.62   \n",
       "557      1           0.67                        0.71  0.62   \n",
       "836      1           0.73                        0.63  0.71   \n",
       "\n",
       "    test preparation course  math score  reading score  writing score  \\\n",
       "29                     0.65        0.62           0.70           0.75   \n",
       "535                    0.73        0.66           0.83           0.83   \n",
       "695                    0.65        0.79           0.89           0.86   \n",
       "557                    0.65        0.61           0.67           0.66   \n",
       "836                    0.65        0.73           0.64           0.57   \n",
       "\n",
       "     avg_scores  \n",
       "29     0.690000  \n",
       "535    0.773333  \n",
       "695    0.846667  \n",
       "557    0.646667  \n",
       "836    0.646667  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#giving each catagory.subcatagory a new normalized value\n",
    "\n",
    "\n",
    "train_set['gender'].values[train_set['gender'] == 'male'] = \"1\"\n",
    "train_set['gender'].values[train_set['gender'] == 'female'] = \"0\"\n",
    "train_set['lunch'].values[train_set['lunch'] == 'standard'] = \"0.71\"\n",
    "train_set['lunch'].values[train_set['lunch'] == 'free/reduced'] = \"0.62\"\n",
    "train_set['test preparation course'].values[train_set['test preparation course'] == 'none'] = \"0.65\"\n",
    "train_set['test preparation course'].values[train_set['test preparation course'] == 'completed'] = \"0.73\"\n",
    "train_set['parental level of education'].values[train_set['parental level of education'] == \"bachelor's degree\"] = \"0.72\"\n",
    "train_set['parental level of education'].values[train_set['parental level of education'] == 'some college'] = \"0.68\"\n",
    "train_set['parental level of education'].values[train_set['parental level of education'] == \"associate's degree\"] = \"0.69\"\n",
    "train_set['parental level of education'].values[train_set['parental level of education'] == \"master's degree\"] = \"0.71\"\n",
    "train_set['parental level of education'].values[train_set['parental level of education'] == 'high school'] = \"0.63\"\n",
    "train_set['parental level of education'].values[train_set['parental level of education'] == 'some high school'] = \"0.65\"\n",
    "train_set['race/ethnicity'].values[train_set['race/ethnicity'] == 'group A'] = \"0.64\"\n",
    "train_set['race/ethnicity'].values[train_set['race/ethnicity'] == 'group B'] = \"0.65\"\n",
    "train_set['race/ethnicity'].values[train_set['race/ethnicity'] == 'group C'] = \"0.67\"\n",
    "train_set['race/ethnicity'].values[train_set['race/ethnicity'] == 'group D'] = \"0.69\"\n",
    "train_set['race/ethnicity'].values[train_set['race/ethnicity'] == 'group E'] = \"0.73\"\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                         float64\n",
      "race/ethnicity                 float64\n",
      "parental level of education    float64\n",
      "lunch                          float64\n",
      "test preparation course        float64\n",
      "math score                     float64\n",
      "reading score                  float64\n",
      "writing score                  float64\n",
      "avg_scores                     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>avg_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.846667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.646667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.646667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  race/ethnicity  parental level of education  lunch  \\\n",
       "29      0.0            0.69                         0.71   0.71   \n",
       "535     0.0            0.67                         0.72   0.62   \n",
       "695     0.0            0.69                         0.68   0.62   \n",
       "557     1.0            0.67                         0.71   0.62   \n",
       "836     1.0            0.73                         0.63   0.71   \n",
       "\n",
       "     test preparation course  math score  reading score  writing score  \\\n",
       "29                      0.65        0.62           0.70           0.75   \n",
       "535                     0.73        0.66           0.83           0.83   \n",
       "695                     0.65        0.79           0.89           0.86   \n",
       "557                     0.65        0.61           0.67           0.66   \n",
       "836                     0.65        0.73           0.64           0.57   \n",
       "\n",
       "     avg_scores  \n",
       "29     0.690000  \n",
       "535    0.773333  \n",
       "695    0.846667  \n",
       "557    0.646667  \n",
       "836    0.646667  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  changing the data type of the columns we changed from object to floats, so that we can compare the data.\n",
    "\n",
    "convert_dict = {'gender': float,\n",
    "                'race/ethnicity':float,\n",
    "                'parental level of education':float,\n",
    "                'lunch':float,\n",
    "                'test preparation course':float,\n",
    "               } \n",
    "\n",
    "train_set = train_set.astype(convert_dict) \n",
    "print(train_set.dtypes) \n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 0.571\n",
      "B 0.6577477477477477\n",
      "C 0.6561016949152545\n",
      "D 0.6854444444444446\n",
      "E 0.6983333333333333\n",
      "\n",
      "S 0.6890983606557376\n",
      "FR 0.619017094017094\n",
      "\n",
      "SHS 0.6222222222222223\n",
      "HS 0.6110810810810812\n",
      "SCO 0.6772727272727272\n",
      "BA 0.6727272727272728\n",
      "M 0.8075\n",
      "AS 0.6818604651162791\n",
      "\n",
      "N 0.6368595041322315\n",
      "CO 0.6999156118143459\n"
     ]
    }
   ],
   "source": [
    "# I want to  to scale the data, so to do that i will cange all catagory.subcatagory to the average of that catagory.subcatagory, values from the avg column then diivde by 100.\n",
    "\n",
    "# scaling the data for the testing set\n",
    "\n",
    "A1=test_set.loc[test_set['race/ethnicity']=='group A']\n",
    "print(\"A\",A1[\"avg_scores\"].mean())\n",
    "B1=test_set.loc[test_set['race/ethnicity']=='group B']\n",
    "print(\"B\",B1[\"avg_scores\"].mean())\n",
    "C1=test_set.loc[test_set['race/ethnicity']=='group C']\n",
    "print(\"C\",C1[\"avg_scores\"].mean())\n",
    "D1=test_set.loc[test_set['race/ethnicity']=='group D']\n",
    "print(\"D\",D1[\"avg_scores\"].mean())\n",
    "E1=test_set.loc[test_set['race/ethnicity']=='group E']\n",
    "print(\"E\",E1[\"avg_scores\"].mean())\n",
    "\n",
    "print()\n",
    "\n",
    "S1=test_set.loc[test_set['lunch']=='standard']\n",
    "print(\"S\",S1[\"avg_scores\"].mean())\n",
    "FR1=test_set.loc[test_set['lunch']=='free/reduced']\n",
    "print(\"FR\",FR1[\"avg_scores\"].mean())\n",
    "\n",
    "print()\n",
    "\n",
    "SHS1=test_set.loc[test_set['parental level of education']=='some high school']\n",
    "print(\"SHS\",SHS1[\"avg_scores\"].mean())\n",
    "HS1=test_set.loc[test_set['parental level of education']=='high school']\n",
    "print(\"HS\",HS1[\"avg_scores\"].mean())\n",
    "SCO1=test_set.loc[test_set['parental level of education']=='some college']\n",
    "print(\"SCO\",SCO1[\"avg_scores\"].mean())\n",
    "BA1=test_set.loc[test_set['parental level of education']==\"bachelor's degree\"]\n",
    "print(\"BA\",BA1[\"avg_scores\"].mean())\n",
    "M1=test_set.loc[test_set['parental level of education']==\"master's degree\"]\n",
    "print(\"M\",M1[\"avg_scores\"].mean())\n",
    "AS1=test_set.loc[test_set['parental level of education']==\"associate's degree\"]\n",
    "print(\"AS\",AS1[\"avg_scores\"].mean())\n",
    "\n",
    "print()\n",
    "\n",
    "N1=test_set.loc[test_set['test preparation course']==\"none\"]\n",
    "print(\"N\",N1[\"avg_scores\"].mean())\n",
    "CO1=test_set.loc[test_set['test preparation course']==\"completed\"]\n",
    "print(\"CO\",CO1[\"avg_scores\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>avg_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gender race/ethnicity parental level of education lunch  \\\n",
       "521      0           0.65                        0.68  0.68   \n",
       "737      0           0.65                        0.67  0.61   \n",
       "740      1           0.68                        0.67  0.68   \n",
       "660      1           0.65                        0.67  0.61   \n",
       "411      1           0.69                        0.67  0.68   \n",
       "\n",
       "    test preparation course  math score  reading score  writing score  \\\n",
       "521                    0.63        0.91           0.86           0.84   \n",
       "737                    0.69        0.53           0.66           0.73   \n",
       "740                    0.63        0.80           0.73           0.72   \n",
       "660                    0.63        0.74           0.77           0.73   \n",
       "411                    0.69        0.84           0.83           0.78   \n",
       "\n",
       "     avg_scores  \n",
       "521    0.870000  \n",
       "737    0.640000  \n",
       "740    0.750000  \n",
       "660    0.746667  \n",
       "411    0.816667  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#giving each catagory.subcatagory a new normalized value\n",
    "\n",
    "test_set['gender'].values[test_set['gender'] == 'male'] = \"1\"\n",
    "test_set['gender'].values[test_set['gender'] == 'female'] = \"0\"\n",
    "test_set['lunch'].values[test_set['lunch'] == 'standard'] = \"0.68\"\n",
    "test_set['lunch'].values[test_set['lunch'] == 'free/reduced'] = \"0.61\"\n",
    "test_set['test preparation course'].values[test_set['test preparation course'] == 'none'] = \"0.63\"\n",
    "test_set['test preparation course'].values[test_set['test preparation course'] == 'completed'] = \"0.69\"\n",
    "test_set['parental level of education'].values[test_set['parental level of education'] == \"bachelor's degree\"] = \"0.67\"\n",
    "test_set['parental level of education'].values[test_set['parental level of education'] == 'some college'] = \"0.67\"\n",
    "test_set['parental level of education'].values[test_set['parental level of education'] == \"associate's degree\"] = \"0.68\"\n",
    "test_set['parental level of education'].values[test_set['parental level of education'] == \"master's degree\"] = \"0.80\"\n",
    "test_set['parental level of education'].values[test_set['parental level of education'] == 'high school'] = \"0.61\"\n",
    "test_set['parental level of education'].values[test_set['parental level of education'] == 'some high school'] = \"0.62\"\n",
    "test_set['race/ethnicity'].values[test_set['race/ethnicity'] == 'group A'] = \"0.57\"\n",
    "test_set['race/ethnicity'].values[test_set['race/ethnicity'] == 'group B'] = \"0.65\"\n",
    "test_set['race/ethnicity'].values[test_set['race/ethnicity'] == 'group C'] = \"0.65\"\n",
    "test_set['race/ethnicity'].values[test_set['race/ethnicity'] == 'group D'] = \"0.68\"\n",
    "test_set['race/ethnicity'].values[test_set['race/ethnicity'] == 'group E'] = \"0.69\"\n",
    "test_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                         float64\n",
      "race/ethnicity                 float64\n",
      "parental level of education    float64\n",
      "lunch                          float64\n",
      "test preparation course        float64\n",
      "math score                     float64\n",
      "reading score                  float64\n",
      "writing score                  float64\n",
      "avg_scores                     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>avg_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.816667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  race/ethnicity  parental level of education  lunch  \\\n",
       "521     0.0            0.65                         0.68   0.68   \n",
       "737     0.0            0.65                         0.67   0.61   \n",
       "740     1.0            0.68                         0.67   0.68   \n",
       "660     1.0            0.65                         0.67   0.61   \n",
       "411     1.0            0.69                         0.67   0.68   \n",
       "\n",
       "     test preparation course  math score  reading score  writing score  \\\n",
       "521                     0.63        0.91           0.86           0.84   \n",
       "737                     0.69        0.53           0.66           0.73   \n",
       "740                     0.63        0.80           0.73           0.72   \n",
       "660                     0.63        0.74           0.77           0.73   \n",
       "411                     0.69        0.84           0.83           0.78   \n",
       "\n",
       "     avg_scores  \n",
       "521    0.870000  \n",
       "737    0.640000  \n",
       "740    0.750000  \n",
       "660    0.746667  \n",
       "411    0.816667  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  changing the data type of the columns we changed from object to floats, so that we can compare the data.\n",
    "\n",
    "convert_dict = {'gender': float,\n",
    "                'race/ethnicity':float,\n",
    "                'parental level of education':float,\n",
    "                'lunch':float,\n",
    "                'test preparation course':float,\n",
    "               } \n",
    "\n",
    "test_set = test_set.astype(convert_dict) \n",
    "print(test_set.dtypes) \n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diving the train and test into x,y\n",
    "\n",
    "X_Train_set1=train_set.loc[:, train_set.columns[1:8]]\n",
    "Y_Train_set1=train_set.loc[:, train_set.columns[0]]\n",
    "X_test_set1=test_set.loc[:, test_set.columns[1:8]]\n",
    "Y_test_set1=test_set.loc[:, test_set.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more imports that i will need\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adaboost 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.1 0.78\n",
      "50 0.2 0.8\n",
      "50 0.30000000000000004 0.845\n",
      "50 0.4 0.855\n",
      "50 0.9 0.86\n",
      "50 1.0 0.875\n",
      "74 0.6 0.885\n"
     ]
    }
   ],
   "source": [
    "count_ada=0\n",
    "b=np.arange(0.1, 1.1, 0.1)\n",
    "for a in range (50,150):\n",
    "    for x in b:\n",
    "        ada = AdaBoostClassifier(random_state=42, n_estimators=a,learning_rate=x)\n",
    "        ada.fit(X_Train_set1, Y_Train_set1)\n",
    "        y_pred_ada = ada.predict(X_test_set1)\n",
    "        a_ada=metrics.accuracy_score(Y_test_set1, y_pred_ada)\n",
    "        if a_ada>count_ada:\n",
    "            count_ada=a_ada\n",
    "            print(a,x, count_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best value for adaboost is with 74 estimators and 0.855 secsess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada1 = AdaBoostClassifier(random_state=42, n_estimators=74,learning_rate=0.6) \n",
    "ada1.fit(X_Train_set1, Y_Train_set1)\n",
    "y_pred_ada1 = ada1.predict(X_test_set1)\n",
    "a_ada1=metrics.accuracy_score(Y_test_set1, y_pred_ada1)\n",
    "a_ada1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90,  7],\n",
       "       [16, 87]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_ada1=confusion_matrix(Y_test_set1, y_pred_ada1)\n",
    "mat_ada1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.925531914893617\n",
      "recall_score: 0.8446601941747572\n",
      "f1_score: 0.883248730964467\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set1, y_pred_ada1)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set1, y_pred_ada1))\n",
    "print(\"f1_score:\",f1_score(Y_test_set1, y_pred_ada1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85625 0.875   0.875   0.85    0.8625 ] mean: 0.8637500000000001\n"
     ]
    }
   ],
   "source": [
    "cv_scores_ada1=cross_val_score(ada1, X_Train_set1, Y_Train_set1, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_ada1, \"mean:\", np.mean(cv_scores_ada1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[371,  50],\n",
       "       [ 59, 320]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_ada1_c = cross_val_predict(ada1,  X_Train_set1, Y_Train_set1, cv=5)\n",
    "cofussion_ada1=confusion_matrix(Y_Train_set1, y_pred_ada1_c)\n",
    "cofussion_ada1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8648648648648649\n",
      "recall_score: 0.8443271767810027\n",
      "f1_score: 0.8544726301735649\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_Train_set1, y_pred_ada1_c)) \n",
    "print(\"recall_score:\",recall_score(Y_Train_set1, y_pred_ada1_c))\n",
    "print(\"f1_score:\",f1_score(Y_Train_set1, y_pred_ada1_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient boosting 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.1 0.485\n",
      "1 0.2 0.63\n",
      "3 0.6 0.645\n",
      "4 0.4 0.675\n",
      "5 0.30000000000000004 0.695\n",
      "5 0.6 0.725\n",
      "6 0.4 0.74\n",
      "6 0.7000000000000001 0.76\n",
      "7 0.5 0.78\n",
      "9 0.9 0.785\n",
      "10 0.5 0.79\n",
      "11 0.5 0.795\n",
      "11 0.7000000000000001 0.815\n",
      "13 0.7000000000000001 0.825\n",
      "13 0.8 0.84\n",
      "13 0.9 0.845\n",
      "14 0.7000000000000001 0.85\n",
      "15 0.7000000000000001 0.855\n",
      "24 0.9 0.86\n",
      "25 0.6 0.865\n",
      "28 0.5 0.87\n",
      "38 1.0 0.875\n",
      "46 0.8 0.89\n"
     ]
    }
   ],
   "source": [
    "count_grb=0\n",
    "b=np.arange(0.1, 1.1, 0.1)\n",
    "for g in range(1,150):\n",
    "    for x in b:\n",
    "        grb=GradientBoostingClassifier(n_estimators=g, learning_rate=x,max_depth=1, random_state=42)\n",
    "        grb.fit(X_Train_set1,Y_Train_set1)\n",
    "        y_pred_grb = grb.predict(X_test_set1)\n",
    "        a_grb=metrics.accuracy_score(Y_test_set1, y_pred_grb)\n",
    "        if a_grb>count_grb:\n",
    "            count_grb= a_grb \n",
    "            print(g, x, a_grb)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best value for gradientboosting is with 46 estimators and a 0.8 learning rate. the secsees is 0.855."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grb1=GradientBoostingClassifier(n_estimators=146, learning_rate=0.8, max_depth=1, random_state=42)\n",
    "grb1.fit(X_Train_set1,Y_Train_set1)\n",
    "y_pred_grb1 = grb1.predict(X_test_set1)\n",
    "a_grb1=metrics.accuracy_score(Y_test_set1, y_pred_grb1)\n",
    "a_grb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89,  8],\n",
       "       [20, 83]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_grb1=confusion_matrix(Y_test_set1, y_pred_grb1)\n",
    "mat_grb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9120879120879121\n",
      "recall_score: 0.8058252427184466\n",
      "f1_score: 0.8556701030927835\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set1, y_pred_grb1)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set1, y_pred_grb1))\n",
    "print(\"f1_score:\",f1_score(Y_test_set1, y_pred_grb1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.875   0.9     0.89375 0.8625  0.875  ] mean: 0.88125\n"
     ]
    }
   ],
   "source": [
    "cv_scores_grb1=cross_val_score(grb1, X_Train_set1, Y_Train_set1, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_grb1, \"mean:\", np.mean(cv_scores_grb1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[376,  45],\n",
       "       [ 50, 329]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_grb1_c = cross_val_predict(grb1,  X_Train_set1, Y_Train_set1, cv=5)\n",
    "cofussion_grb1=confusion_matrix(Y_Train_set1, y_pred_grb1_c)\n",
    "cofussion_grb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8796791443850267\n",
      "recall_score: 0.8680738786279684\n",
      "f1_score: 0.8738379814077025\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_Train_set1, y_pred_grb1_c)) \n",
    "print(\"recall_score:\",recall_score(Y_Train_set1, y_pred_grb1_c))\n",
    "print(\"f1_score:\",f1_score(Y_Train_set1, y_pred_grb1_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.87\n",
      "61 0.89\n",
      "73 0.9\n",
      "89 0.905\n",
      "92 0.91\n",
      "93 0.915\n",
      "105 0.92\n",
      "146 0.925\n",
      "148 0.93\n"
     ]
    }
   ],
   "source": [
    "xg_count=0\n",
    "for x in range(50,150):\n",
    "    xg=XGBClassifier(n_estimators=x, max_depth=2, eta=0.1, subsample=0.7, colsample_bytree=0.8,\n",
    "                 use_label_encoder =False,eval_metric = \"logloss\")\n",
    "    xg.fit(X_Train_set1, Y_Train_set1)\n",
    "    y_pred_xg = xg.predict(X_test_set1)\n",
    "    a_xg=metrics.accuracy_score(Y_test_set1, y_pred_xg)\n",
    "    if a_xg>xg_count:\n",
    "        xg_count=a_xg\n",
    "        print(x, a_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best value for XGboost is with 148 estimators and the secsees is 0.93."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg1=XGBClassifier(n_estimators=148, max_depth=2, eta=0.1, subsample=0.7, colsample_bytree=0.8,\n",
    "                 use_label_encoder =False,eval_metric = \"logloss\")\n",
    "xg1.fit(X_Train_set1, Y_Train_set1)\n",
    "y_pred_xg1 = xg1.predict(X_test_set1)\n",
    "a_xg1=metrics.accuracy_score(Y_test_set1, y_pred_xg1)\n",
    "a_xg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92,  5],\n",
       "       [ 9, 94]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_xg1=confusion_matrix(Y_test_set1, y_pred_xg1)\n",
    "mat_xg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9494949494949495\n",
      "recall_score: 0.912621359223301\n",
      "f1_score: 0.9306930693069307\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set1, y_pred_xg1)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set1, y_pred_xg1))\n",
    "print(\"f1_score:\",f1_score(Y_test_set1, y_pred_xg1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8875  0.8875  0.88125 0.84375 0.86875] mean: 0.87375\n"
     ]
    }
   ],
   "source": [
    "cv_scores_xg1=cross_val_score(xg1, X_Train_set1, Y_Train_set1, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_xg1, \"mean:\", np.mean(cv_scores_xg1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[377,  44],\n",
       "       [ 57, 322]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_xg1_c = cross_val_predict(xg1,  X_Train_set1, Y_Train_set1, cv=5)\n",
    "cofussion_xg1=confusion_matrix(Y_Train_set1, y_pred_xg1_c)\n",
    "cofussion_xg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8797814207650273\n",
      "recall_score: 0.8496042216358839\n",
      "f1_score: 0.8644295302013422\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_Train_set1, y_pred_xg1_c)) \n",
    "print(\"recall_score:\",recall_score(Y_Train_set1, y_pred_xg1_c))\n",
    "print(\"f1_score:\",f1_score(Y_Train_set1, y_pred_xg1_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "come back to later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# voting classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> 0.885\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> 0.86\n",
      "<class 'xgboost.sklearn.XGBClassifier'> 0.93\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> 0.895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.895"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote1=VotingClassifier(estimators=[('ada1', ada1),('gradient1', grb1),('xg1',xg1)], voting='soft', weights=[0.3,0.3,0.5])\n",
    "vote1.fit(X_Train_set1, Y_Train_set1)\n",
    "for clf in(ada1, grb1, xg1, vote1):\n",
    "    clf.fit(X_Train_set1, Y_Train_set1) \n",
    "    y_pred_vote1=clf.predict(X_test_set1)\n",
    "    print(clf.__class__ ,accuracy_score(Y_test_set1,y_pred_vote1))\n",
    "a_vote1=metrics.accuracy_score(Y_test_set1, y_pred_vote1)\n",
    "a_vote1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the secsees value for voting classifier is 0.895."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91,  6],\n",
       "       [15, 88]], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_vote1=confusion_matrix(Y_test_set1, y_pred_vote1)\n",
    "mat_vote1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9361702127659575\n",
      "recall_score: 0.8543689320388349\n",
      "f1_score: 0.8934010152284263\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set1, y_pred_vote1)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set1, y_pred_vote1))\n",
    "print(\"f1_score:\",f1_score(Y_test_set1, y_pred_vote1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86875 0.8875  0.89375 0.85    0.8625 ] mean: 0.8725000000000002\n"
     ]
    }
   ],
   "source": [
    "cv_scores_vote1=cross_val_score(vote1, X_Train_set1, Y_Train_set1, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_vote1, \"mean:\", np.mean(cv_scores_vote1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[375,  46],\n",
       "       [ 56, 323]], dtype=int64)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_vote1_c = cross_val_predict(vote1,  X_Train_set1, Y_Train_set1, cv=5)\n",
    "cofussion_vote1=confusion_matrix(Y_Train_set1, y_pred_vote1_c)\n",
    "cofussion_vote1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8753387533875339\n",
      "recall_score: 0.8522427440633246\n",
      "f1_score: 0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_Train_set1, y_pred_vote1_c)) \n",
    "print(\"recall_score:\",recall_score(Y_Train_set1, y_pred_vote1_c))\n",
    "print(\"f1_score:\",f1_score(Y_Train_set1, y_pred_vote1_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the best secsees using all the columns is 0.93 using XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to get better resullts only using the columns with the scores\n",
    "X_Train_set2=train_set.loc[:, train_set.columns[5:8]]\n",
    "Y_Train_set2=train_set.loc[:, train_set.columns[0]]\n",
    "X_test_set2=test_set.loc[:, test_set.columns[5:8]]\n",
    "Y_test_set2=test_set.loc[:, test_set.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     math score  reading score  writing score\n",
       "29         0.62           0.70           0.75\n",
       "535        0.66           0.83           0.83\n",
       "695        0.79           0.89           0.86\n",
       "557        0.61           0.67           0.66\n",
       "836        0.73           0.64           0.57"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train_set2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adaboost 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.1 0.78\n",
      "50 0.2 0.8\n",
      "50 0.30000000000000004 0.855\n",
      "50 0.4 0.86\n",
      "50 0.5 0.87\n",
      "50 0.6 0.875\n",
      "63 0.9 0.88\n",
      "64 0.6 0.885\n",
      "72 0.7000000000000001 0.89\n"
     ]
    }
   ],
   "source": [
    "count_ada2=0\n",
    "b=np.arange(0.1, 1.1, 0.1)\n",
    "for a in range (50,150):\n",
    "    for x in b:\n",
    "        ada2 = AdaBoostClassifier(random_state=42, n_estimators=a, learning_rate=x)\n",
    "        ada2.fit(X_Train_set2, Y_Train_set2)\n",
    "        y_pred_ada2 = ada2.predict(X_test_set2)\n",
    "        a_ada2=metrics.accuracy_score(Y_test_set2, y_pred_ada2)\n",
    "        if a_ada2>count_ada2:\n",
    "            count_ada2=a_ada2\n",
    "            print(a,x,count_ada2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best value for adaboost is with 72 estimators and 0.89 secsess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada2 = AdaBoostClassifier(random_state=42, n_estimators=72, learning_rate=0.7)\n",
    "ada2.fit(X_Train_set2, Y_Train_set2)\n",
    "y_pred_ada2 = ada2.predict(X_test_set2)\n",
    "a_ada2=metrics.accuracy_score(Y_test_set2, y_pred_ada2)\n",
    "a_ada2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89,  8],\n",
       "       [14, 89]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_ada2=confusion_matrix(Y_test_set2, y_pred_ada2)\n",
    "mat_ada2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9175257731958762\n",
      "recall_score: 0.8640776699029126\n",
      "f1_score: 0.89\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set2, y_pred_ada2)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set2, y_pred_ada2))\n",
    "print(\"f1_score:\",f1_score(Y_test_set2, y_pred_ada2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85625 0.825   0.825   0.8     0.8125 ] mean: 0.8237499999999999\n"
     ]
    }
   ],
   "source": [
    "cv_scores_ada2=cross_val_score(ada2, X_Train_set2, Y_Train_set2, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_ada2, \"mean:\", np.mean(cv_scores_ada2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[346,  75],\n",
       "       [ 66, 313]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_ada2_c = cross_val_predict(ada2,  X_Train_set2, Y_Train_set2, cv=5)\n",
    "cofussion_ada2=confusion_matrix(Y_Train_set2, y_pred_ada2_c)\n",
    "cofussion_ada2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8067010309278351\n",
      "recall_score: 0.8258575197889182\n",
      "f1_score: 0.8161668839634941\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_Train_set2, y_pred_ada2_c)) \n",
    "print(\"recall_score:\",recall_score(Y_Train_set2, y_pred_ada2_c))\n",
    "print(\"f1_score:\",f1_score(Y_Train_set2, y_pred_ada2_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient boosting 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.1 0.78\n",
      "50 0.2 0.835\n",
      "50 0.30000000000000004 0.84\n",
      "50 0.4 0.845\n",
      "50 0.5 0.865\n",
      "50 0.6 0.87\n",
      "50 0.7000000000000001 0.875\n",
      "50 1.0 0.88\n",
      "69 1.0 0.885\n",
      "89 0.9 0.89\n",
      "159 0.6 0.895\n"
     ]
    }
   ],
   "source": [
    "count_grb2=0\n",
    "b=np.arange(0.1, 1.1, 0.1)\n",
    "for g in range(50,200):\n",
    "    for x in b:\n",
    "        grb2=GradientBoostingClassifier(n_estimators=g, learning_rate=x,max_depth=1, random_state=42)\n",
    "        grb2.fit(X_Train_set2,Y_Train_set2)\n",
    "        y_pred_grb2 = grb2.predict(X_test_set2)\n",
    "        a_grb2=metrics.accuracy_score(Y_test_set2, y_pred_grb2)\n",
    "        if a_grb2>count_grb2:\n",
    "            count_grb2= a_grb2 \n",
    "            print(g, x, a_grb2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best value for gradientboosting is with 159 estimators and a 0.6 learning rate. the secsees is 0.895."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.895"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grb2=GradientBoostingClassifier(n_estimators=159, learning_rate=0.6,max_depth=1, random_state=42)\n",
    "grb2.fit(X_Train_set2,Y_Train_set2)\n",
    "y_pred_grb2 = grb2.predict(X_test_set2)\n",
    "a_grb2=metrics.accuracy_score(Y_test_set2, y_pred_grb2)\n",
    "a_grb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89,  8],\n",
       "       [13, 90]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_grb2=confusion_matrix(Y_test_set2, y_pred_grb2)\n",
    "mat_grb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9183673469387755\n",
      "recall_score: 0.8737864077669902\n",
      "f1_score: 0.8955223880597014\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set2, y_pred_grb2)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set2,y_pred_grb2 ))\n",
    "print(\"f1_score:\",f1_score(Y_test_set2, y_pred_grb2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85    0.85    0.8375  0.78125 0.7875 ] mean: 0.82125\n"
     ]
    }
   ],
   "source": [
    "cv_scores_grb2=cross_val_score(grb2, X_Train_set2, Y_Train_set2, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_grb2, \"mean:\", np.mean(cv_scores_grb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[350,  71],\n",
       "       [ 72, 307]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_grb2_c = cross_val_predict(grb2,  X_Train_set2, Y_Train_set2, cv=5)\n",
    "cofussion_grb2=confusion_matrix(Y_Train_set1, y_pred_grb2_c)\n",
    "cofussion_grb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score_train: 0.8121693121693122\n",
      "recall_score_train: 0.8100263852242744\n",
      "f1_score_train: 0.8110964332892999\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score_train:\",precision_score(Y_Train_set2, y_pred_grb2_c)) \n",
    "print(\"recall_score_train:\",recall_score(Y_Train_set2, y_pred_grb2_c))\n",
    "print(\"f1_score_train:\",f1_score(Y_Train_set2, y_pred_grb2_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.83\n",
      "51 0.835\n",
      "52 0.84\n",
      "53 0.845\n",
      "55 0.85\n",
      "56 0.86\n",
      "57 0.865\n",
      "73 0.87\n",
      "80 0.875\n",
      "84 0.88\n",
      "93 0.885\n",
      "94 0.89\n",
      "99 0.895\n"
     ]
    }
   ],
   "source": [
    "xg_count2=0\n",
    "for x in range(50,200):\n",
    "    xg2=XGBClassifier(n_estimators=x, max_depth=2, eta=0.1, subsample=0.7, colsample_bytree=0.8,\n",
    "                 use_label_encoder =False,eval_metric = \"logloss\")\n",
    "    xg2.fit(X_Train_set2, Y_Train_set2)\n",
    "    y_pred_xg2 = xg2.predict(X_test_set2)\n",
    "    a_xg2=metrics.accuracy_score(Y_test_set2, y_pred_xg2)\n",
    "    if a_xg2>xg_count2:\n",
    "        xg_count2=a_xg2\n",
    "        print(x, a_xg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best value for XGboost is with 99 estimators and the secsees is 0.895."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.895"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg2=XGBClassifier(n_estimators=99, max_depth=2, eta=0.1, subsample=0.7, colsample_bytree=0.8,\n",
    "                 use_label_encoder =False,eval_metric = \"logloss\")\n",
    "xg2.fit(X_Train_set2, Y_Train_set2)\n",
    "y_pred_xg2 = xg2.predict(X_test_set2)\n",
    "a_xg2=metrics.accuracy_score(Y_test_set2, y_pred_xg2)\n",
    "a_xg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90,  7],\n",
       "       [14, 89]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_xg2=confusion_matrix(Y_test_set2, y_pred_xg2)\n",
    "mat_xg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9270833333333334\n",
      "recall_score: 0.8640776699029126\n",
      "f1_score: 0.8944723618090452\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set2, y_pred_xg2)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set2, y_pred_xg2))\n",
    "print(\"f1_score:\",f1_score(Y_test_set2, y_pred_xg2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8625  0.84375 0.825   0.80625 0.83125] mean: 0.83375\n"
     ]
    }
   ],
   "source": [
    "cv_scores_xg2=cross_val_score(xg2, X_Train_set2, Y_Train_set2, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_xg2, \"mean:\", np.mean(cv_scores_xg2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[358,  63],\n",
       "       [ 70, 309]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_xg2_c = cross_val_predict(xg2,  X_Train_set2, Y_Train_set2, cv=5)\n",
    "cofussion_xg2=confusion_matrix(Y_Train_set2, y_pred_xg2_c)\n",
    "cofussion_xg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8306451612903226\n",
      "recall_score: 0.8153034300791556\n",
      "f1_score: 0.8229027962716379\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_Train_set2, y_pred_xg2_c)) \n",
    "print(\"recall_score:\",recall_score(Y_Train_set2, y_pred_xg2_c))\n",
    "print(\"f1_score:\",f1_score(Y_Train_set2, y_pred_xg2_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "come back to later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# voting classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> 0.89\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> 0.895\n",
      "<class 'xgboost.sklearn.XGBClassifier'> 0.895\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> 0.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote2=VotingClassifier(estimators=[('ada2', ada2),('gradient2', grb2),('xg2',xg)], voting='soft',weights=[0.33,0.33,0.34])\n",
    "vote2.fit(X_Train_set2, Y_Train_set2)\n",
    "for clf in(ada2, grb2, xg2, vote2):\n",
    "    clf.fit(X_Train_set2, Y_Train_set2) \n",
    "    y_pred_vote2=clf.predict(X_test_set2)\n",
    "    print(clf.__class__ ,accuracy_score(Y_test_set2,y_pred_vote2))\n",
    "a_vote2=metrics.accuracy_score(Y_test_set2, y_pred_vote2)\n",
    "a_vote2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the secsees value for voting classifier is 0.89."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89,  8],\n",
       "       [14, 89]], dtype=int64)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_vote2=confusion_matrix(Y_test_set2, y_pred_vote2)\n",
    "mat_vote2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9175257731958762\n",
      "recall_score: 0.8640776699029126\n",
      "f1_score: 0.89\n"
     ]
    }
   ],
   "source": [
    "mat_vote2=confusion_matrix(Y_test_set2, y_pred_vote2)\n",
    "mat_vote2\n",
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set2, y_pred_vote2)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set2, y_pred_vote2))\n",
    "print(\"f1_score:\",f1_score(Y_test_set2, y_pred_vote2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8625  0.85    0.81875 0.8     0.80625] mean: 0.8275\n"
     ]
    }
   ],
   "source": [
    "cv_scores_vote2=cross_val_score(vote2, X_Train_set2, Y_Train_set2, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_vote2, \"mean:\", np.mean(cv_scores_vote2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[352,  69],\n",
       "       [ 69, 310]], dtype=int64)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_vote2_c = cross_val_predict(vote2,  X_Train_set2, Y_Train_set2, cv=5)\n",
    "cofussion_vote2=confusion_matrix(Y_Train_set2, y_pred_vote2_c)\n",
    "cofussion_vote2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8179419525065963\n",
      "recall_score: 0.8179419525065963\n",
      "f1_score: 0.8179419525065962\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_Train_set2, y_pred_vote2_c)) \n",
    "print(\"recall_score:\",recall_score(Y_Train_set2, y_pred_vote2_c))\n",
    "print(\"f1_score:\",f1_score(Y_Train_set2, y_pred_vote2_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the best secsees using the columns with the scores is 0.895, with gradientboosting, XGboost, and voting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>avg_scores</th>\n",
       "      <th>other avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.6850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  race/ethnicity  parental level of education  lunch  \\\n",
       "29      0.0            0.69                         0.71   0.71   \n",
       "535     0.0            0.67                         0.72   0.62   \n",
       "695     0.0            0.69                         0.68   0.62   \n",
       "557     1.0            0.67                         0.71   0.62   \n",
       "836     1.0            0.73                         0.63   0.71   \n",
       "\n",
       "     test preparation course  math score  reading score  writing score  \\\n",
       "29                      0.65        0.62           0.70           0.75   \n",
       "535                     0.73        0.66           0.83           0.83   \n",
       "695                     0.65        0.79           0.89           0.86   \n",
       "557                     0.65        0.61           0.67           0.66   \n",
       "836                     0.65        0.73           0.64           0.57   \n",
       "\n",
       "     avg_scores  other avg  \n",
       "29     0.690000     0.6900  \n",
       "535    0.773333     0.6850  \n",
       "695    0.846667     0.6600  \n",
       "557    0.646667     0.6625  \n",
       "836    0.646667     0.6800  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding a new column with the average of the columns that arent the scores in the train set\n",
    "avg_train=train_set.loc[:, train_set.columns[1:5]]\n",
    "train_set['other avg']=avg_train.mean(axis=1)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>avg_scores</th>\n",
       "      <th>other avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.6550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.6650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.6825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  race/ethnicity  parental level of education  lunch  \\\n",
       "521     0.0            0.65                         0.68   0.68   \n",
       "737     0.0            0.65                         0.67   0.61   \n",
       "740     1.0            0.68                         0.67   0.68   \n",
       "660     1.0            0.65                         0.67   0.61   \n",
       "411     1.0            0.69                         0.67   0.68   \n",
       "\n",
       "     test preparation course  math score  reading score  writing score  \\\n",
       "521                     0.63        0.91           0.86           0.84   \n",
       "737                     0.69        0.53           0.66           0.73   \n",
       "740                     0.63        0.80           0.73           0.72   \n",
       "660                     0.63        0.74           0.77           0.73   \n",
       "411                     0.69        0.84           0.83           0.78   \n",
       "\n",
       "     avg_scores  other avg  \n",
       "521    0.870000     0.6600  \n",
       "737    0.640000     0.6550  \n",
       "740    0.750000     0.6650  \n",
       "660    0.746667     0.6400  \n",
       "411    0.816667     0.6825  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding a new column with the average of the columns that arent the scores in the test set\n",
    "avg_test=test_set.loc[:, test_set.columns[1:5]]\n",
    "test_set['other avg']=avg_test.mean(axis=1)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the data set be the scores and both the averages\n",
    "X_Train_set3=train_set.loc[:, train_set.columns[5:10]]\n",
    "Y_Train_set3=train_set.loc[:, train_set.columns[0]]\n",
    "X_test_set3=test_set.loc[:, test_set.columns[5:10]]\n",
    "Y_test_set3=test_set.loc[:, test_set.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>avg_scores</th>\n",
       "      <th>other avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.66</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.6850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0.6800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     math score  reading score  writing score  avg_scores  other avg\n",
       "29         0.62           0.70           0.75    0.690000     0.6900\n",
       "535        0.66           0.83           0.83    0.773333     0.6850\n",
       "695        0.79           0.89           0.86    0.846667     0.6600\n",
       "557        0.61           0.67           0.66    0.646667     0.6625\n",
       "836        0.73           0.64           0.57    0.646667     0.6800"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train_set3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adaboost 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.1 0.78\n",
      "50 0.2 0.8\n",
      "50 0.30000000000000004 0.855\n",
      "50 0.7000000000000001 0.875\n",
      "50 0.9 0.88\n",
      "115 0.6 0.885\n"
     ]
    }
   ],
   "source": [
    "count_ada3=0\n",
    "b=np.arange(0.1, 1.1, 0.1)\n",
    "for a in range (50,150):\n",
    "    for x in b:\n",
    "        ada3 = AdaBoostClassifier(random_state=42, n_estimators=a,learning_rate=x)\n",
    "        ada3.fit(X_Train_set3, Y_Train_set3)\n",
    "        y_pred_ada3 = ada3.predict(X_test_set3)\n",
    "        a_ada3=metrics.accuracy_score(Y_test_set3, y_pred_ada3)\n",
    "        if a_ada3>count_ada3:\n",
    "            count_ada3=a_ada3\n",
    "            print(a, x, count_ada3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best value for adaboost is with 115 estimators and 0.885 secsess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada3 = AdaBoostClassifier(random_state=42, n_estimators=115,learning_rate=0.6)\n",
    "ada3.fit(X_Train_set3, Y_Train_set3)\n",
    "y_pred_ada3 = ada3.predict(X_test_set3)\n",
    "a_ada3=metrics.accuracy_score(Y_test_set3, y_pred_ada3)\n",
    "a_ada3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89,  8],\n",
       "       [15, 88]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_ada3=confusion_matrix(Y_test_set3, y_pred_ada3)\n",
    "mat_ada3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9166666666666666\n",
      "recall_score: 0.8543689320388349\n",
      "f1_score: 0.8844221105527638\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set3, y_pred_ada3)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set3, y_pred_ada3))\n",
    "print(\"f1_score:\",f1_score(Y_test_set3, y_pred_ada3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86875 0.8625  0.81875 0.80625 0.83125] mean: 0.8375\n"
     ]
    }
   ],
   "source": [
    "cv_scores_ada3=cross_val_score(ada3, X_Train_set3, Y_Train_set3, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_ada3, \"mean:\", np.mean(cv_scores_ada3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[354,  67],\n",
       "       [ 63, 316]], dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_ada3_c = cross_val_predict(ada3,  X_Train_set3, Y_Train_set3, cv=5)\n",
    "cofussion_ada3=confusion_matrix(Y_Train_set3, y_pred_ada3_c)\n",
    "cofussion_ada3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score_train: 0.825065274151436\n",
      "recall_score_train: 0.8337730870712401\n",
      "f1_score_train: 0.8293963254593176\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score_train:\",precision_score(Y_Train_set3, y_pred_ada3_c)) \n",
    "print(\"recall_score_train:\",recall_score(Y_Train_set3, y_pred_ada3_c))\n",
    "print(\"f1_score_train:\",f1_score(Y_Train_set3, y_pred_ada3_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient boosting 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.1 0.485\n",
      "1 0.2 0.63\n",
      "3 0.6 0.645\n",
      "4 0.4 0.675\n",
      "5 0.30000000000000004 0.695\n",
      "5 0.6 0.725\n",
      "6 0.4 0.74\n",
      "6 0.7000000000000001 0.76\n",
      "7 0.5 0.78\n",
      "9 0.9 0.785\n",
      "10 0.5 0.79\n",
      "11 0.5 0.795\n",
      "11 0.7000000000000001 0.815\n",
      "13 0.7000000000000001 0.825\n",
      "13 0.8 0.84\n",
      "13 0.9 0.845\n",
      "14 0.7000000000000001 0.85\n",
      "15 0.7000000000000001 0.855\n",
      "15 0.8 0.865\n",
      "21 0.7000000000000001 0.875\n",
      "40 0.9 0.88\n",
      "48 0.8 0.885\n",
      "81 0.7000000000000001 0.89\n"
     ]
    }
   ],
   "source": [
    "count_grb3=0\n",
    "b=np.arange(0.1, 1.1, 0.1)\n",
    "for g in range(1,150):\n",
    "    for x in b:\n",
    "        grb3=GradientBoostingClassifier(n_estimators=g, learning_rate=x,max_depth=1, random_state=42)\n",
    "        grb3.fit(X_Train_set3,Y_Train_set3)\n",
    "        y_pred_grb3 = grb3.predict(X_test_set3)\n",
    "        a_grb3=metrics.accuracy_score(Y_test_set3, y_pred_grb3)\n",
    "        if a_grb3>count_grb3:\n",
    "            count_grb3= a_grb3 \n",
    "            print(g,x, a_grb3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best value for gradientboosting is with 81 estimators and a 0.7 learning rate. the secsees is 0.89."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grb3=GradientBoostingClassifier(n_estimators=81, learning_rate=0.7,max_depth=1, random_state=42)\n",
    "grb3.fit(X_Train_set3,Y_Train_set3)\n",
    "y_pred_grb3 = grb3.predict(X_test_set3)\n",
    "a_grb3=metrics.accuracy_score(Y_test_set3, y_pred_grb3)\n",
    "a_grb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[91,  6],\n",
       "       [16, 87]], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_grb3=confusion_matrix(Y_test_set3, y_pred_grb3)\n",
    "mat_grb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9354838709677419\n",
      "recall_score: 0.8446601941747572\n",
      "f1_score: 0.8877551020408163\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set3, y_pred_grb3)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set3,y_pred_grb3 ))\n",
    "print(\"f1_score:\",f1_score(Y_test_set3, y_pred_grb3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85625 0.85    0.81875 0.78125 0.83125] mean: 0.8275\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "cv_scores_grb3=cross_val_score(grb3, X_Train_set3, Y_Train_set3, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_grb3, \"mean:\", np.mean(cv_scores_grb3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[357,  64],\n",
       "       [ 74, 305]], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_grb3_c = cross_val_predict(grb3,  X_Train_set3, Y_Train_set3, cv=5)\n",
    "cofussion_grb3=confusion_matrix(Y_Train_set3, y_pred_grb3_c)\n",
    "cofussion_grb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8265582655826558\n",
      "recall_score: 0.8047493403693932\n",
      "f1_score: 0.8155080213903743\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_Train_set3, y_pred_grb3_c)) \n",
    "print(\"recall_score:\",recall_score(Y_Train_set3, y_pred_grb3_c))\n",
    "print(\"f1_score:\",f1_score(Y_Train_set3, y_pred_grb3_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 0.855\n",
      "54 0.865\n",
      "55 0.87\n",
      "76 0.88\n"
     ]
    }
   ],
   "source": [
    "xg_count3=0\n",
    "for x in range (50,200):\n",
    "    xg3=XGBClassifier(n_estimators=x, max_depth=2, eta=0.1, subsample=0.7, colsample_bytree=0.8,\n",
    "                 use_label_encoder =False,eval_metric = \"logloss\")\n",
    "    xg3.fit(X_Train_set3, Y_Train_set3)\n",
    "    y_pred_xg3 = xg3.predict(X_test_set3)\n",
    "    a_xg3=metrics.accuracy_score(Y_test_set3, y_pred_xg3)\n",
    "    if a_xg3>xg_count3:\n",
    "        xg_count3=a_xg3\n",
    "        print(x, a_xg3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best value for XGboost is with 76 estimators and the secsees is 0.88."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg3=XGBClassifier(n_estimators=76, max_depth=2, eta=0.1, subsample=0.7, colsample_bytree=0.8,\n",
    "                 use_label_encoder =False,eval_metric = \"logloss\")\n",
    "xg3.fit(X_Train_set3, Y_Train_set3)\n",
    "y_pred_xg3 = xg3.predict(X_test_set3)\n",
    "a_xg3=metrics.accuracy_score(Y_test_set3, y_pred_xg3)\n",
    "a_xg3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90,  7],\n",
       "       [17, 86]], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_xg3=confusion_matrix(Y_test_set3, y_pred_xg3)\n",
    "mat_xg3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9247311827956989\n",
      "recall_score: 0.8349514563106796\n",
      "f1_score: 0.8775510204081631\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set3, y_pred_xg3)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set3, y_pred_xg3))\n",
    "print(\"f1_score:\",f1_score(Y_test_set3, y_pred_xg3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8375  0.85625 0.825   0.80625 0.8375 ] mean: 0.8324999999999999\n"
     ]
    }
   ],
   "source": [
    "cv_scores_xg3=cross_val_score(xg3, X_Train_set3, Y_Train_set3, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_xg3, \"mean:\", np.mean(cv_scores_xg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[361,  60],\n",
       "       [ 74, 305]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_xg3_c = cross_val_predict(xg3,  X_Train_set3, Y_Train_set3, cv=5)\n",
    "cofussion_xg3=confusion_matrix(Y_Train_set3, y_pred_xg3_c)\n",
    "cofussion_xg3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8356164383561644\n",
      "recall_score: 0.8047493403693932\n",
      "f1_score: 0.8198924731182796\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_Train_set3, y_pred_xg3_c)) \n",
    "print(\"recall_score:\",recall_score(Y_Train_set3, y_pred_xg3_c))\n",
    "print(\"f1_score:\",f1_score(Y_Train_set3, y_pred_xg3_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# voting classifier 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'> 0.885\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'> 0.89\n",
      "<class 'xgboost.sklearn.XGBClassifier'> 0.88\n",
      "<class 'sklearn.ensemble._voting.VotingClassifier'> 0.885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.885"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote3=VotingClassifier(estimators=[('ada3', ada3),('gradient3', grb3),('xg2',xg3)], voting='soft',weights=[0.3,0.4,0.3])\n",
    "vote3.fit(X_Train_set3, Y_Train_set3)\n",
    "for clf in(ada3, grb3, xg3, vote3):\n",
    "    clf.fit(X_Train_set3, Y_Train_set3) \n",
    "    y_pred_vote3=clf.predict(X_test_set3)\n",
    "    print(clf.__class__ ,accuracy_score(Y_test_set3,y_pred_vote3))\n",
    "a_vote3=metrics.accuracy_score(Y_test_set3, y_pred_vote3)\n",
    "a_vote3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the secsees value for voting classifier is 0.885."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_vote3=confusion_matrix(Y_test_set3, y_pred_vote3)\n",
    "mat_vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.9166666666666666\n",
      "recall_score: 0.8543689320388349\n",
      "f1_score: 0.8844221105527638\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_test_set3, y_pred_vote3)) \n",
    "print(\"recall_score:\",recall_score(Y_test_set3, y_pred_vote3))\n",
    "print(\"f1_score:\",f1_score(Y_test_set3, y_pred_vote3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85625 0.84375 0.825   0.79375 0.83125] mean: 0.8299999999999998\n"
     ]
    }
   ],
   "source": [
    "cv_scores_vote3=cross_val_score(vote3, X_Train_set3, Y_Train_set3, cv=5, scoring=\"accuracy\")\n",
    "print(cv_scores_vote3, \"mean:\", np.mean(cv_scores_vote3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[356,  65],\n",
       "       [ 71, 308]], dtype=int64)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confussion matrix\n",
    "y_pred_vote3_c = cross_val_predict(vote3,  X_Train_set3, Y_Train_set3, cv=5)\n",
    "cofussion_vote3=confusion_matrix(Y_Train_set3, y_pred_vote3_c)\n",
    "cofussion_vote3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.8257372654155496\n",
      "recall_score: 0.8126649076517151\n",
      "f1_score: 0.8191489361702128\n"
     ]
    }
   ],
   "source": [
    "# precision call, recalll score, f1 score\n",
    "print(\"precision_score:\",precision_score(Y_Train_set3, y_pred_vote3_c)) \n",
    "print(\"recall_score:\",recall_score(Y_Train_set3, y_pred_vote3_c))\n",
    "print(\"f1_score:\",f1_score(Y_Train_set3, y_pred_vote3_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_ada1: 0.885\n",
      "a_ada2: 0.89\n",
      "a_ada3: 0.885\n",
      "a_grb1: 0.86\n",
      "a_grb2: 0.895\n",
      "a_grb3: 0.89\n",
      "a_xg1: 0.93\n",
      "a_xg2: 0.895\n",
      "a_xg3: 0.88\n",
      "a_xg3: 0.88\n",
      "a_vote1: 0.895\n",
      "a_vote2: 0.89\n",
      "a_vote3: 0.885\n"
     ]
    }
   ],
   "source": [
    "print(\"a_ada1:\" ,a_ada1)\n",
    "print(\"a_ada2:\" ,a_ada2)\n",
    "print(\"a_ada3:\" ,a_ada3)\n",
    "print(\"a_grb1:\" ,a_grb1)\n",
    "print(\"a_grb2:\" ,a_grb2)\n",
    "print(\"a_grb3:\" ,a_grb3)\n",
    "print(\"a_xg1:\" ,a_xg1)\n",
    "print(\"a_xg2:\" ,a_xg2)\n",
    "print(\"a_xg3:\" ,a_xg3)\n",
    "print(\"a_xg3:\" ,a_xg3)\n",
    "print(\"a_vote1:\" ,a_vote1)\n",
    "print(\"a_vote2:\" ,a_vote2)\n",
    "print(\"a_vote3:\" ,a_vote3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the best results were gradientboost and xgboost only using the scores, and voting using all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_scores_ada1 [0.85625 0.875   0.875   0.85    0.8625 ] mean: 0.8637500000000001\n",
      "cv_scores_ada2 [0.85625 0.825   0.825   0.8     0.8125 ] mean: 0.8237499999999999\n",
      "cv_scores_ada3 [0.86875 0.8625  0.81875 0.80625 0.83125] mean: 0.8375\n",
      "cv_scores_grb1 [0.875   0.9     0.89375 0.8625  0.875  ] mean: 0.88125\n",
      "cv_scores_grb2 [0.85    0.85    0.8375  0.78125 0.7875 ] mean: 0.82125\n",
      "cv_scores_grb3 [0.85625 0.85    0.81875 0.78125 0.83125] mean: 0.8275\n",
      "cv_scores_xg1 [0.8875  0.8875  0.88125 0.84375 0.86875] mean: 0.87375\n",
      "cv_scores_xg2 [0.8625  0.84375 0.825   0.80625 0.83125] mean: 0.83375\n",
      "cv_scores_xg3 [0.8375  0.85625 0.825   0.80625 0.8375 ] mean: 0.8324999999999999\n",
      "cv_scores_vote1 [0.86875 0.8875  0.89375 0.85    0.8625 ] mean: 0.8725000000000002\n",
      "cv_scores_vote2 [0.8625  0.85    0.81875 0.8     0.80625] mean: 0.8275\n",
      "cv_scores_vote3 [0.85625 0.84375 0.825   0.79375 0.83125] mean: 0.8299999999999998\n"
     ]
    }
   ],
   "source": [
    "print(\"cv_scores_ada1\",cv_scores_ada1, \"mean:\", np.mean(cv_scores_ada1))\n",
    "print(\"cv_scores_ada2\",cv_scores_ada2, \"mean:\", np.mean(cv_scores_ada2))\n",
    "print(\"cv_scores_ada3\",cv_scores_ada3, \"mean:\", np.mean(cv_scores_ada3))\n",
    "print(\"cv_scores_grb1\",cv_scores_grb1, \"mean:\", np.mean(cv_scores_grb1))\n",
    "print(\"cv_scores_grb2\",cv_scores_grb2, \"mean:\", np.mean(cv_scores_grb2))\n",
    "print(\"cv_scores_grb3\",cv_scores_grb3, \"mean:\", np.mean(cv_scores_grb3))\n",
    "print(\"cv_scores_xg1\",cv_scores_xg1, \"mean:\", np.mean(cv_scores_xg1))\n",
    "print(\"cv_scores_xg2\",cv_scores_xg2, \"mean:\", np.mean(cv_scores_xg2))\n",
    "print(\"cv_scores_xg3\",cv_scores_xg3, \"mean:\", np.mean(cv_scores_xg3))\n",
    "print(\"cv_scores_vote1\",cv_scores_vote1, \"mean:\", np.mean(cv_scores_vote1))\n",
    "print(\"cv_scores_vote2\",cv_scores_vote2, \"mean:\", np.mean(cv_scores_vote2))\n",
    "print(\"cv_scores_vote3\",cv_scores_vote3, \"mean:\", np.mean(cv_scores_vote3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when doing the cross validation the best results is gradiantboodt using all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
